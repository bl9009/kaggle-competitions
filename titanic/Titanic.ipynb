{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble    import RandomForestClassifier\n",
    "from sklearn.ensemble    import AdaBoostClassifier\n",
    "from sklearn.neighbors   import KNeighborsClassifier\n",
    "from sklearn.svm         import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw     = pandas.read_csv(\"data/train.csv\")\n",
    "dataTestRaw = pandas.read_csv(\"data/test.csv\")\n",
    "\n",
    "# take a peak into data\n",
    "dataRaw.head()\n",
    "\n",
    "# some initial (logical) considerations:\n",
    "# 1. 'Survived' does obviously not depend on 'Name' or 'PassengerId'\n",
    "# 2. Same for 'Embarked' (at least I can't see any reasonable connection), but cross-check to be sure\n",
    "# 3. 'Sex' and 'Age' might have strong influence on survival (\"Women and children first!\")\n",
    "# 4. There might be a strong correlation between 'Fare' and 'Pclass',\n",
    "#    which might also be strongly correlated to 'Survived' -> feature extraction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataRaw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRaw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insights:\n",
    "# - 'Ticket' contains useless information, same for 'Cabin' which holds majorly NaNs -> drop\n",
    "# - 'Age' needs to be imputed (mean? median?)\n",
    "# - Missing 'Embarked' need to be added (only 2 values missing, just add most frequent category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for further inspection\n",
    "dataDirty = dataRaw.copy()\n",
    "\n",
    "# convert 'Sex', and 'Embarked' to 'category' and encode with integers\n",
    "dataDirty['Sex']      = dataRaw['Sex'].astype('category').cat.codes\n",
    "dataDirty['Embarked'] = dataRaw['Embarked'].astype('category').cat.codes\n",
    "\n",
    "# drop unneeded features\n",
    "#dataDirty.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# drop labels 'Survived'\n",
    "#dataDirty.drop('Survived', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation matrix\n",
    "corrMatrix = dataDirty.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       1.000000\n",
       "Fare           0.257307\n",
       "Parch          0.081629\n",
       "PassengerId   -0.005007\n",
       "SibSp         -0.035322\n",
       "Age           -0.077221\n",
       "Embarked      -0.176509\n",
       "Pclass        -0.338481\n",
       "Sex           -0.543351\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrMatrix['Survived'].sort_values(ascending=False)\n",
    "\n",
    "# Insights:\n",
    "# - 'Survived' has strong correlation with 'Fare',\n",
    "#   and strong negative correlation with 'Pclass', and 'Sex'.\n",
    "# - Correlation with 'Age' is not as strong as expected\n",
    "# - 'Parch' and 'SibSp' are apparently not very relevant for 'Survived'\n",
    "# - 'Embarked' has higher importance than expected, worth to dig deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked       1.000000\n",
       "Pclass         0.173511\n",
       "Sex            0.118492\n",
       "SibSp          0.071480\n",
       "Parch          0.043351\n",
       "PassengerId    0.012985\n",
       "Age           -0.044830\n",
       "Survived      -0.176509\n",
       "Fare          -0.230365\n",
       "Name: Embarked, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrMatrix['Embarked'].sort_values(ascending=False)\n",
    "\n",
    "# Insights:\n",
    "# - 'Embarked' is somehow correlated to 'Pclass', and 'Sex'\n",
    "# - Relatively strong negative correlation with 'Fare' (meaning \n",
    "#   in some ports tickets were probably more expensive, but is\n",
    "#   this relevant for this specific problem?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training\n",
    "\n",
    "# set up pipelines for:\n",
    "# - converting pandas dataframe in numpy ndarray\n",
    "# - dropping bad data ('Tickets', 'Cabin', 'PassengerId', 'Name')\n",
    "# - impute missing data ('Age', 'Embarked')\n",
    "# - Normalize 'Age' and 'Fare' values\n",
    "# - one-hot encode 'Embarked' and 'Sex'\n",
    "        \n",
    "class DataFrameSelector(TransformerMixin):\n",
    "    def __init__(self, attributeIds):\n",
    "        self.attributeIds = attributeIds\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attributeIds]\n",
    "    \n",
    "class DataFrameConverter(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.values\n",
    "    \n",
    "class OneHotCatEncoder(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        catEncoder    = LabelEncoder()\n",
    "        oneHotEncoder = OneHotEncoder()\n",
    "        \n",
    "        catEncoded = catEncoder.fit_transform(X.values.ravel())\n",
    "        \n",
    "        encoded = oneHotEncoder.fit_transform(catEncoded.reshape(-1,1))\n",
    "        \n",
    "        return pandas.DataFrame(oneHotEncoder.fit_transform(catEncoded.reshape(-1,1)).toarray())\n",
    "    \n",
    "class CatImputer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        mostFreqCat = X.iloc[0].value_counts().idxmax()\n",
    "        \n",
    "        return X.fillna(mostFreqCat)\n",
    "        \n",
    "\n",
    "# one-hot encode and impute 'Embarked'\n",
    "embarkedPipeline = Pipeline([\n",
    "    ('selector' , DataFrameSelector(['Embarked'])),\n",
    "    ('imputer'  , CatImputer()),\n",
    "    ('encoder'  , OneHotCatEncoder()),\n",
    "    ('converter', DataFrameConverter())\n",
    "])\n",
    "\n",
    "# one-hot encode 'Sex'\n",
    "sexPipeline = Pipeline([\n",
    "    ('selector' , DataFrameSelector(['Sex'])),\n",
    "    ('encoder'  , OneHotCatEncoder()),\n",
    "    ('converter', DataFrameConverter())\n",
    "])\n",
    "\n",
    "# impute and normalize 'Age'\n",
    "agePipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['Age'])),\n",
    "    ('imputor' , Imputer(strategy='mean')),\n",
    "    ('scaler'  , StandardScaler())\n",
    "])\n",
    "\n",
    "# normalize 'Fare'\n",
    "farePipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['Fare'])),\n",
    "    ('imputor' , Imputer(strategy='mean')),\n",
    "    ('scaler'  , StandardScaler())\n",
    "])\n",
    "\n",
    "# select remaining attributes\n",
    "remPipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(['Pclass']))\n",
    "])\n",
    "\n",
    "pipeline = FeatureUnion(transformer_list=[\n",
    "    ('embarkedPipeline', embarkedPipeline),\n",
    "    ('sexPipeline'     , sexPipeline),\n",
    "    ('agePipeline'     , agePipeline),\n",
    "    ('farePipeline'    , farePipeline),\n",
    "    ('remPipeline'     , remPipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features and labels\n",
    "dataTrain  = dataRaw.drop('Survived', axis=1)\n",
    "dataLabels = dataRaw['Survived'].copy()\n",
    "\n",
    "# run data through pipeline\n",
    "dataTrainPrepared = pipeline.fit_transform(dataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model selection\n",
    "\n",
    "clsfRandomForest = RandomForestClassifier()\n",
    "clsfSVC          = SVC()\n",
    "clsfNaiveBayes   = GaussianNB()\n",
    "clsfKNN          = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 20,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate RandomForestClassifier\n",
    "\n",
    "paramGrid = [\n",
    "    {'n_estimators': [10, 20, 25, 30, 35]\n",
    "   , 'max_depth'   : [10, 20, 30]\n",
    "   , 'max_features': [1, 2, 3, 4, 5, 6]\n",
    "   , 'min_samples_split': [2, 3, 4, 5, 6]\n",
    "   , 'min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "   , 'random_state': [42]}\n",
    "]\n",
    "\n",
    "gridSearch = GridSearchCV(clsfRandomForest, paramGrid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gridSearch.fit(dataTrainPrepared, dataLabels)\n",
    "\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79461279,  0.82154882,  0.82491582])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsfRandomForest = RandomForestClassifier(max_depth=10, max_features=2, n_estimators=20, random_state=42)\n",
    "\n",
    "cross_val_score(clsfRandomForest, dataTrainPrepared, dataLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93378226711560042"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check over-/underfitting\n",
    "\n",
    "clsfRandomForest.fit(dataTrainPrepared, dataLabels)\n",
    "\n",
    "predictions = clsfRandomForest.predict(dataTrainPrepared)\n",
    "\n",
    "accuracy_score(dataLabels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2.0, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate SVC\n",
    "\n",
    "paramGrid = [\n",
    "    { 'C': [0.5, 1.0, 2.0, 4.0, 5.0]\n",
    "    , 'kernel': ['linear', 'rbf', 'poly']}\n",
    "]\n",
    "\n",
    "gridSearch = GridSearchCV(clsfSVC, paramGrid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gridSearch.fit(dataTrainPrepared, dataLabels)\n",
    "\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79461279,  0.84175084,  0.81818182])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsfSVC = SVC(C=2.0, kernel='rbf')\n",
    "\n",
    "cross_val_score(clsfSVC, dataTrainPrepared, dataLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82828282828282829"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check over-/underfitting\n",
    "\n",
    "clsfSVC.fit(dataTrainPrepared, dataLabels)\n",
    "\n",
    "predictions = clsfSVC.predict(dataTrainPrepared)\n",
    "\n",
    "accuracy_score(dataLabels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73400673,  0.77777778,  0.77104377])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate Naive Bayes\n",
    "\n",
    "cross_val_score(clsfNaiveBayes, dataTrainPrepared, dataLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 5, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate KNearestNeighbors\n",
    "\n",
    "paramGrid = [\n",
    "    {'n_neighbors': [1, 3, 5, 10, 15, 20, 25, 30], 'weights': ['uniform', 'distance']},\n",
    "]\n",
    "\n",
    "gridSearch = GridSearchCV(clsfKNN, paramGrid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "gridSearch.fit(dataTrainPrepared, dataLabels)\n",
    "\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78451178,  0.81818182,  0.81481481])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clsfKNN = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "cross_val_score(clsfKNN, dataTrainPrepared, dataLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC is the most promising model,\n",
    "# so train it with whole training set\n",
    "# and validate against test set\n",
    "\n",
    "# prepare test data\n",
    "dataTestPrepared = pipeline.fit_transform(dataTestRaw)\n",
    "\n",
    "# train model and do predictions\n",
    "clsfSVC.fit(dataTrainPrepared, dataLabels)\n",
    "\n",
    "predictions = clsfSVC.predict(dataTestPrepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submission = pandas.DataFrame({\n",
    "    'PassengerId': dataTestRaw['PassengerId'],\n",
    "    'Survived'   : predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
